{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e7eee3-af9c-4501-82c3-3a9f3ab8d536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 41188 | Positives: 4640 (11.27%)\n",
      "Numeric cols: ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
      "Categorical cols: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
      "Validation AUC — LR: 0.9367 | RF: 0.9439\n",
      "Selected: Random Forest (Val AUC=0.9439)\n",
      "Best threshold (F1 on val): 0.398\n",
      "==== Test (Default) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9371    0.9518      5483\n",
      "           1     0.6016    0.7486    0.6671       696\n",
      "\n",
      "    accuracy                         0.9158      6179\n",
      "   macro avg     0.7843    0.8428    0.8095      6179\n",
      "weighted avg     0.9259    0.9158    0.9198      6179\n",
      "\n",
      "==== Test (Tuned) ====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9820    0.9042    0.9415      5483\n",
      "           1     0.5354    0.8693    0.6627       696\n",
      "\n",
      "    accuracy                         0.9003      6179\n",
      "   macro avg     0.7587    0.8868    0.8021      6179\n",
      "weighted avg     0.9317    0.9003    0.9101      6179\n",
      "\n",
      "\n",
      "=== Done! Check folders ===\n",
      "Plots -> task1_plots_opt\n",
      "Artifacts -> task1_artifacts\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Task 1 – Optimized Pipeline for Bank Marketing (Term Deposit)\n",
    "# Works with: bank-additional-full.csv (semicolon-delimited)\n",
    "# =========================\n",
    "\n",
    "# ---- Imports\n",
    "import os, json, textwrap, warnings, joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    classification_report, f1_score, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, accuracy_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "# ---- Paths / output dirs\n",
    "DATA_CSV = \"bank-additional-full.csv\"        # path to your CSV\n",
    "PLOTS_DIR = \"task1_plots_opt\"\n",
    "ARTIFACTS_DIR = \"task1_artifacts\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 1) Load & Prepare\n",
    "# =========================\n",
    "df = pd.read_csv(DATA_CSV, sep=';')\n",
    "df['y'] = df['y'].map({'yes':1, 'no':0})\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "\n",
    "print(f\"Rows: {len(df)} | Positives: {int(y.sum())} ({y.mean():.2%})\")\n",
    "print(\"Numeric cols:\", numeric_cols)\n",
    "print(\"Categorical cols:\", categorical_cols)\n",
    "\n",
    "# Split 70/15/15\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.1765, random_state=42, stratify=y_train_full\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 2) Preprocessing (fixed OneHotEncoder)\n",
    "# =========================\n",
    "# Compatibility: sklearn>=1.2 uses sparse_output, older uses sparse\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "pre_lr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([('scaler', StandardScaler())]), numeric_cols),\n",
    "        ('cat', ohe, categorical_cols),\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "pre_rf = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_cols),\n",
    "        ('cat', ohe, categorical_cols),\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) Build Models\n",
    "# =========================\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocess', pre_lr),\n",
    "    ('model', LogisticRegression(max_iter=4000, class_weight='balanced', C=2.0, solver='lbfgs', random_state=42))\n",
    "])\n",
    "\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocess', pre_rf),\n",
    "    ('model', RandomForestClassifier(\n",
    "        n_estimators=500, max_depth=None,\n",
    "        min_samples_split=4, min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced_subsample',\n",
    "        n_jobs=-1, random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================\n",
    "# 4) Train & Select Best Model (Validation AUC)\n",
    "# =========================\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "val_auc_lr = roc_auc_score(y_val, pipe_lr.predict_proba(X_val)[:,1])\n",
    "val_auc_rf = roc_auc_score(y_val, pipe_rf.predict_proba(X_val)[:,1])\n",
    "\n",
    "if val_auc_lr >= val_auc_rf:\n",
    "    best_estimator = pipe_lr\n",
    "    best_name = \"Logistic Regression\"\n",
    "    best_val_auc = val_auc_lr\n",
    "else:\n",
    "    best_estimator = pipe_rf\n",
    "    best_name = \"Random Forest\"\n",
    "    best_val_auc = val_auc_rf\n",
    "\n",
    "print(f\"Validation AUC — LR: {val_auc_lr:.4f} | RF: {val_auc_rf:.4f}\")\n",
    "print(f\"Selected: {best_name} (Val AUC={best_val_auc:.4f})\")\n",
    "\n",
    "# =========================\n",
    "# 5) Threshold Tuning\n",
    "# =========================\n",
    "y_val_proba = best_estimator.predict_proba(X_val)[:,1]\n",
    "prec, rec, thr = precision_recall_curve(y_val, y_val_proba)\n",
    "f1s = 2*(prec*rec) / (prec+rec + 1e-12)\n",
    "best_thr_idx = int(np.nanargmax(f1s))\n",
    "best_threshold = 0.5 if best_thr_idx >= len(thr) else float(thr[best_thr_idx])\n",
    "print(f\"Best threshold (F1 on val): {best_threshold:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 6) Refit on Train+Val, Evaluate on Test\n",
    "# =========================\n",
    "best_estimator.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "y_test_proba = best_estimator.predict_proba(X_test)[:,1]\n",
    "y_test_pred_default = (y_test_proba >= 0.5).astype(int)\n",
    "y_test_pred_tuned   = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "def eval_pack(y_true, y_pred, y_prob, label):\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred)),\n",
    "        \"auc\": float(roc_auc_score(y_true, y_prob)),\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist(),\n",
    "        \"classification_report\": classification_report(y_true, y_pred, digits=4)\n",
    "    }\n",
    "\n",
    "m_default = eval_pack(y_test, y_test_pred_default, y_test_proba, \"Default 0.5\")\n",
    "m_tuned   = eval_pack(y_test, y_test_pred_tuned,   y_test_proba, f\"Tuned {best_threshold:.3f}\")\n",
    "\n",
    "print(\"==== Test (Default) ====\")\n",
    "print(m_default[\"classification_report\"])\n",
    "print(\"==== Test (Tuned) ====\")\n",
    "print(m_tuned[\"classification_report\"])\n",
    "\n",
    "# =========================\n",
    "# 7) Plots\n",
    "# =========================\n",
    "# Confusion matrices\n",
    "for m in [m_default, m_tuned]:\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    ConfusionMatrixDisplay(confusion_matrix=np.array(m[\"confusion_matrix\"]), display_labels=[\"No\",\"Yes\"]).plot(\n",
    "        ax=ax, values_format=\"d\", colorbar=False\n",
    "    )\n",
    "    ax.set_title(f\"{best_name} – {m['label']}\")\n",
    "    fig.savefig(os.path.join(PLOTS_DIR, f\"confusion_{m['label'].replace(' ','_')}.png\"))\n",
    "    plt.close(fig)\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(fpr, tpr, label=f\"{best_name} (AUC={roc_auc_score(y_test, y_test_proba):.3f})\")\n",
    "ax.plot([0,1],[0,1],'--')\n",
    "ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"ROC Curve (Test)\")\n",
    "ax.legend()\n",
    "fig.savefig(os.path.join(PLOTS_DIR, \"roc_curve.png\"))\n",
    "plt.close(fig)\n",
    "\n",
    "# Precision-Recall (Val)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(rec, prec, label=\"PR (val)\")\n",
    "ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\")\n",
    "ax.set_title(\"Precision-Recall (Validation)\")\n",
    "ax.legend()\n",
    "fig.savefig(os.path.join(PLOTS_DIR, \"precision_recall_val.png\"))\n",
    "plt.close(fig)\n",
    "\n",
    "# =========================\n",
    "# 8) Feature Importances\n",
    "# =========================\n",
    "try:\n",
    "    feat_names = best_estimator.named_steps['preprocess'].get_feature_names_out()\n",
    "    model = best_estimator.named_steps['model']\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "    else:\n",
    "        importances = np.abs(model.coef_.ravel())\n",
    "\n",
    "    top_idx = np.argsort(importances)[-20:][::-1]\n",
    "    top_feats = np.array(feat_names)[top_idx]\n",
    "    top_vals  = importances[top_idx]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.barh(range(len(top_feats)), top_vals)\n",
    "    ax.set_yticks(range(len(top_feats))); ax.set_yticklabels(top_feats)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(\"Top Features\")\n",
    "    fig.savefig(os.path.join(PLOTS_DIR, \"top_features.png\"))\n",
    "    plt.close(fig)\n",
    "except Exception as e:\n",
    "    print(\"Feature importance plot skipped:\", e)\n",
    "\n",
    "# =========================\n",
    "# 9) Save Artifacts\n",
    "# =========================\n",
    "best_model_path = os.path.join(ARTIFACTS_DIR, \"best_model_pipeline.joblib\")\n",
    "joblib.dump(best_estimator, best_model_path)\n",
    "\n",
    "meta = {\n",
    "    \"best_model\": best_name,\n",
    "    \"validation_auc\": float(best_val_auc),\n",
    "    \"validation_best_threshold\": float(best_threshold),\n",
    "    \"metrics_test_default\": m_default,\n",
    "    \"metrics_test_tuned\": m_tuned,\n",
    "}\n",
    "metrics_json_path = os.path.join(ARTIFACTS_DIR, \"metrics_and_config.json\")\n",
    "with open(metrics_json_path, \"w\") as f: json.dump(meta, f, indent=2)\n",
    "\n",
    "# Simple CLI inference\n",
    "inference_py_path = os.path.join(ARTIFACTS_DIR, \"inference.py\")\n",
    "with open(inference_py_path, \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "import joblib, pandas as pd, sys\n",
    "THRESHOLD = {best_threshold:.6f}\n",
    "pipe = joblib.load('best_model_pipeline.joblib')\n",
    "df = pd.read_csv(sys.argv[1], sep=';')\n",
    "if 'y' in df.columns: df = df.drop(columns=['y'])\n",
    "p = pipe.predict_proba(df)[:,1]\n",
    "out = pd.DataFrame({{'proba':p, 'pred':(p>=THRESHOLD).astype(int)}})\n",
    "out.to_csv('predictions.csv', index=False)\n",
    "print('Saved predictions.csv')\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n=== Done! Check folders ===\")\n",
    "print(\"Plots ->\", PLOTS_DIR)\n",
    "print(\"Artifacts ->\", ARTIFACTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cfc83-8c62-4cc6-8270-750fdbaf6272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
